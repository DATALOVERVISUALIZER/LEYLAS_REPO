{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EventsExport\n",
    "This notebook look inside all the events sequences that appeair often. This is then saved into a json file for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pyspark import SparkContext, SparkConf, StorageLevel\n",
    "from pyspark.sql import HiveContext, Row\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, date\n",
    "import calendar\n",
    "import time, logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.path as path\n",
    "import operator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs_churn = '/user/hadoop/churn_project' # Shared folder for storing Churn files\n",
    "hdfs_churn_sas = hdfs_churn + '/sas_data'\n",
    "period = '2015_04'\n",
    "tablePath = \"/eventsMonthly\" # relative path # events_repart # eventsRedif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.setCheckpointDir('checkpointSpark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading Event Explanation for Converting Letter, for displaying \n",
    "cols=[\"Conc\", \"Letter\", \"MDLevent\", \"Refined Names\"]\n",
    "EventsDef=pd.read_csv('../EventDefExplanation.csv',delimiter=';',skiprows=1,names=cols)\n",
    "\n",
    "print len(EventsDef)\n",
    "\n",
    "conversionDict = {}\n",
    "for i in range(len(EventsDef)):\n",
    "    conversionDict[EventsDef[\"Letter\"][i]]=EventsDef[\"Refined Names\"][i]\n",
    "\n",
    "#Add Churning Event\n",
    "conversionDict[\"CE\"] = \"ChurningEvent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Segments = ['Cluster2','Cluster6','Cluster10','Cluster12','Cluster4']\n",
    "def filterSegment(col):\n",
    "    cond = \"\"\n",
    "    for s in Segments:\n",
    "        cond = cond + col + \" = '\" + s + \"' or \"\n",
    "    return cond[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading Parquet file \n",
    "start = time.time()\n",
    "eventsParquet = sqlContext.read.parquet(hdfs_churn+tablePath)\n",
    "#if not useVal: #Then filder Sample=Training ...\n",
    "#eventsParquet = eventsParquet.filter(\"SEGMENT = 'Cluster10'\")\n",
    "#eventsParquet = eventsParquet.filter(filterSegment('SEGMENT')) # Filter only the segments we need\n",
    "#eventsParquet = eventsParquet.filter(\"period='\"+period+\"'\")\n",
    "eventsParquet = eventsParquet.filter(\"Churn=1\")\n",
    "eventsParquet.persist(StorageLevel.MEMORY_ONLY)\n",
    "eventsParquet.registerTempTable(\"events\")\n",
    "print eventsParquet.printSchema()\n",
    "eventsParquet = eventsParquet.sort([\"period\", \"customer_number\", \"datetime\", \"letter\"]) # Be careful there is an order sort the event def\n",
    "print eventsParquet.take(1)\n",
    "\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_events = \"\"\"\n",
    "SELECT\n",
    "    period,\n",
    "    customer_number,\n",
    "    letter as event,\n",
    "    Churn as churn,\n",
    "    SEGMENT as segment\n",
    "FROM events a\n",
    "ORDER BY period, customer_number, datetime, letter\n",
    "\"\"\"\n",
    "# Should be 284 different event\n",
    "\n",
    "eventsForPatterns = sqlContext.sql(query_events)\n",
    "eventsForPatterns.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cache rdd of events\n",
    "events = eventsForPatterns.rdd.map(lambda (per, cn, e, f, s): ((cn, (f,s), per), e))\n",
    "print eventsForPatterns.take(1)\n",
    "# events is now in the right form for computing ngrams; key: (CustomerNumber, Flag) value: Event\n",
    "events.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute variables and histograms on Events\n",
    "Variables are required for computing patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute number of customer\n",
    "print events.take(1)\n",
    "customerDistinct = events.map(lambda ((cn, fs, per), e): (cn,fs)).distinct()\n",
    "nbrCustomer = customerDistinct.count()\n",
    "nbrChurningCustomer = customerDistinct.filter(lambda (cn, (f,s)): f==1).count()\n",
    "nbrNonChurningCustomer = nbrCustomer-nbrChurningCustomer\n",
    "print \"Number of Total customer in the Event table:       \" + str(nbrCustomer)\n",
    "print \"Number of Churning customer in the Event table:    \" + str(nbrChurningCustomer)\n",
    "print \"Number of NonChurning customer in the Event table: \" + str(nbrNonChurningCustomer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Compute patterns (Prepare events list for each customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hybrid way for computing patterns\n",
    "eventsWithIndex = events.zipWithIndex() \\\n",
    "                        .map(lambda ((customer, event),index): (customer, (event, index)))\n",
    "eventsGrouped = eventsWithIndex.groupByKey()\n",
    "#eventsGrouped.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "    \n",
    "# Function to convert Iterable to List, in the RIGHT order\n",
    "def convIterable(it):\n",
    "    lst = list(it)\n",
    "    \n",
    "    #Order the list\n",
    "    def getIndex(item):\n",
    "        return item[1]\n",
    "    lst = sorted(lst, key=getIndex)\n",
    "    \n",
    "    #Remove index\n",
    "    lst = [row[0] for row in lst]\n",
    "    \n",
    "    return tuple(lst) # Convertion to tuple because it needs to be hashable\n",
    "\n",
    "# Function to add Churning event at the end of the sequence of Churning customers\n",
    "def addChurningEvent(eventList, flag):\n",
    "    if flag == 1:\n",
    "        return eventList + (u\"CE\", )\n",
    "    else:\n",
    "        return eventList\n",
    "\n",
    "eventsGroupedList = eventsGrouped.mapValues(lambda it: convIterable(it))\n",
    "eventsGroupedList = eventsGroupedList.map(lambda ((cn, (f,s), per), eventList): ((cn, (f,s), per), addChurningEvent(eventList,f)))\n",
    "eventsGroupedList.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eventsGroupedList.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eventsGroupedList.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createLinks(eventsList):\n",
    "    linksList = []\n",
    "    if len(eventsList) < 2:\n",
    "        return linksList\n",
    "    \n",
    "    source = eventsList[0]\n",
    "    first = True\n",
    "    i = 0\n",
    "    for event in eventsList:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        i = i + 1\n",
    "        \n",
    "        depth = len(eventsList) - i - 1\n",
    "        \n",
    "        target = event\n",
    "        linksList.append((source, target, depth))\n",
    "        source = target\n",
    "        \n",
    "    return linksList\n",
    "        \n",
    "eventsLinksList = eventsGroupedList.mapValues(lambda events: createLinks(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eventsLinksList.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x): return x\n",
    "eventsLinksListFlat = eventsLinksList.flatMapValues(f)\n",
    "eventsLinksListFlat.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linksRdd = eventsLinksListFlat.map(lambda ((cn, (f, seg), per), link): ((seg, link), 1))\n",
    "linksRdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linksReduced = linksRdd.reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linksReduced.cache()\n",
    "print linksReduced.take(1)\n",
    "print Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each segment run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Segment = \"Cluster4\"\n",
    "\n",
    "if Segment == \"AllCluster\":\n",
    "    linksReducedSegment = linksReduced.map(lambda ((seg, link), nbr): (link, nbr)).reduceByKey(lambda a,b: a+b)\n",
    "else:\n",
    "    linksReducedSegment = linksReduced.filter(lambda ((seg, link), nbr): seg == Segment).map(lambda ((seg, link), nbr): (link, nbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linksCollect = linksReducedSegment.sortBy(lambda (k,v): v, False).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter and formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxDeep = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Max/min value, based on the maximun number of links\n",
    "maxLink = maxDeep * 30\n",
    "\n",
    "maxLink = min(maxLink, len(linksCollect)-1)\n",
    "minValue = linksCollect[maxLink][1]\n",
    "print maxLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number linksCollect: \" + str(len(linksCollect))\n",
    "\n",
    "links = []\n",
    "eventDict = {}\n",
    "for ((source, target, depth), value) in linksCollect:\n",
    "    if value < minValue:\n",
    "        continue\n",
    "    if depth > maxDeep:\n",
    "        continue\n",
    "        \n",
    "    sourceD = (source, depth+1)\n",
    "    targetD = (target, depth)\n",
    "        \n",
    "    if sourceD not in eventDict:\n",
    "        eventDict[sourceD] = len(eventDict)\n",
    "    if targetD not in eventDict:\n",
    "        eventDict[targetD] = len(eventDict)\n",
    "    \n",
    "    #Source ad Target switched for chronology, not required here\n",
    "    links.append({'source': eventDict[sourceD], 'target': eventDict[targetD], 'value': value})\n",
    "    \n",
    "print \"Number links: \" + str(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eventDictSorted = sorted(eventDict.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for (event, depth), i in eventDictSorted:\n",
    "    nodes.append({'name': conversionDict[event], 'id': str(i), 'depth': depth})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of nodes: \" + str(len(nodes))\n",
    "print \"Number of links: \" + str(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalJson = {}\n",
    "finalJson['nodes'] = nodes\n",
    "finalJson['links'] = links\n",
    "\n",
    "with open('input/AllEvents' + Segment + '.json', 'w') as outfile:\n",
    "    json.dump(finalJson, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_output": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}